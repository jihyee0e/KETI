import streamlit as st
import pandas as pd
from langchain_community.llms import Ollama
from analysis_utils import extract_text_from_file, robust_code_extractor, run_analysis, display_uploaded_files
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import io
import contextlib
import matplotlib.pyplot as plt
import re
import fitz  # PyMuPDF
from analysis_utils import get_file_hash

st.set_page_config(layout="wide")
st.title("Local LLM Analysis Agent")

st.sidebar.title("âœ… Select version")
mode = st.sidebar.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”", ["Combined View", "Split View"])
st.sidebar.markdown("<br>", unsafe_allow_html=True)

llm = Ollama(
    base_url="http://localhost:11434",
    model="llama3.2:latest",
    temperature=0.3,
)

def deduplicate_files(files):
    seen_hashes = set()
    unique = []
    duplicates = []

    for file in files:
        file_hash = get_file_hash(file)
        if file_hash not in seen_hashes:
            seen_hashes.add(file_hash)
            unique.append(file)
        else:
            duplicates.append(file.name)
    return unique, duplicates

# ------------------------------
# Combined view
# ------------------------------
if mode == "Combined View":
    if "dedup_files" not in st.session_state:
        st.session_state["dedup_files"] = []
    if "duplicates" not in st.session_state:
        st.session_state["duplicates"] = []

    uploaded_files = st.file_uploader(
        "ğŸ“‚ Upload your files", type=["csv", "pdf", "txt"], accept_multiple_files=True
    )

    if not uploaded_files:
        st.session_state["dedup_files"] = []
        st.session_state["duplicate_names"] = []
    else:
        # dedup ê°±ì‹ : í•´ì‹œ ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        unique_files, duplicates = deduplicate_files(uploaded_files)
        st.session_state["dedup_files"] = unique_files
        st.session_state["duplicate_names"] = list(set(duplicates))

    # ì¤‘ë³µ ê²½ê³  ì¶œë ¥
    for dup in st.session_state.get("duplicate_names", []):
        st.warning(f"âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤: {dup}")

    if st.session_state.get("dedup_files"):
        display_uploaded_files(st.session_state["dedup_files"], llm, key_prefix="combined")

# ------------------------------
# Split view
# ------------------------------
# ------------------------------
# Split view
# ------------------------------
elif mode == "Split View":
    if "dedup_files_split" not in st.session_state:
        st.session_state["dedup_files_split"] = []
    if "duplicates_split" not in st.session_state:
        st.session_state["duplicates_split"] = []

    uploaded_files = st.sidebar.file_uploader(
        "ğŸ“‚ Upload your files", type=["csv", "pdf", "txt"], accept_multiple_files=True
    )
    if uploaded_files:
        unique_files, duplicates = deduplicate_files(uploaded_files)
        st.session_state["dedup_files_split"] = unique_files
        st.session_state["duplicates_split"] = list(set(duplicates))
    else:
        st.session_state["dedup_files_split"] = []
        st.session_state["duplicates_split"] = []

    for dup in st.session_state.get("duplicates_split", []):
        st.sidebar.warning(f"âš ï¸ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤: {dup}")

    if st.session_state["dedup_files_split"]:
        display_uploaded_files(
            st.session_state["dedup_files_split"],
            llm,
            key_prefix="split",
            sidebar_mode=True
        )