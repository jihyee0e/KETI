# Transformer-chatbot 

## ğŸ“Œ í”„ë¡œì íŠ¸ ëª©ì 

  Transformer ê¸°ë°˜ ì±—ë´‡ êµ¬í˜„: Transformer êµ¬ì¡°ë¥¼ êµ¬í˜„í•˜ì—¬ ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ ì±—ë´‡ì„ ë§Œë“œëŠ” í•™ìŠµìš© í”„ë¡œì íŠ¸
  - RAG(Retrieval-Augmented Generation)ë¥¼ í™œìš©í•˜ì—¬ ì™¸ë¶€ ë¬¸ì„œë¥¼ ê²€ìƒ‰ í›„ ë¬¸ë§¥ì„ ë°˜ì˜í•œ ì‘ë‹µì„ ìƒì„±
  - Agent (..ing)

## ğŸ“‚ í´ë” êµ¬ì¡°
```
Transformer-chatbot/   
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ChatBotData.csv      â† í•™ìŠµìš© ë°ì´í„°, ìµœì´ˆ ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ
â”œâ”€â”€ model/                   # í•™ìŠµëœ ëª¨ë¸ ì €ì¥ í´ë”  
â”‚   â”œâ”€â”€ chatbot_model.keras  â† í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ (.keras)
â”‚   â””â”€â”€ tokenizer.pickle     â† í•™ìŠµëœ í† í¬ë‚˜ì´ì € (.pickle)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ rag_index.py         â† ë¬¸ì„œ ì„ë² ë”© í›„ FAISS ì¸ë±ìŠ¤ ìƒì„± (RAG ê²€ìƒ‰ìš©)
â”‚   â”œâ”€â”€ run.py               â† ì‹¤í–‰ ì œì–´
â”‚   â”œâ”€â”€ inference.py         â† ì±—ë´‡ ì‘ë‹µ ìƒì„± (ëª¨ë¸ + í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì™€ì„œ ì¶”ë¡ )
â”‚   â”œâ”€â”€ mask_schedule.py     â† ë§ˆìŠ¤í¬ ìƒì„± ë° ì»¤ìŠ¤í…€ í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì˜
â”‚   â”œâ”€â”€ model.py             â† Transformer êµ¬ì¡° ì •ì˜ (ì¸ì½”ë”, ë””ì½”ë”, ì „ì²´ ëª¨ë¸)
â”‚   â”œâ”€â”€ tokenizer.py         â† Subword í† í¬ë‚˜ì´ì € ìƒì„± í•¨ìˆ˜ ì •ì˜
â”‚   â””â”€â”€ train.py             â† í•™ìŠµ íŒŒì´í”„ë¼ì¸ (ëª¨ë¸ í•™ìŠµ + ì €ì¥)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸ§± ì „ì²´ êµ¬ì¡° ìš”ì•½
  ```
  plaintext
  [ì…ë ¥ ë¬¸ì¥] 
     â†“
  [ì¸ì½”ë” (self-attention)]
     â†“
  [ë””ì½”ë” (look-ahead + enc-dec attention)]
     â†“
  [ì¶œë ¥ì¸µ Dense â†’ ë‹¨ì–´ ì˜ˆì¸¡]
  ```

## ğŸ§­ ì±—ë´‡ êµ¬í˜„ íë¦„

  1. ë°ì´í„° ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•
  2. ë§ˆìŠ¤í¬ ìƒì„± (`create_padding_mask`, `create_look_ahead_mask`)
  3. ì¸ì½”ë”/ë””ì½”ë” ë ˆì´ì–´ êµ¬ì„± (`encoder_layer`, `decoder_layer`)
  4. ì „ì²´ ëª¨ë¸ êµ¬ì„± (`transformer`)
  5. í•™ìŠµ ë£¨í”„ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
  6. ì¶”ë¡  ë¡œì§: í•œ ê¸€ìì”© ìƒì„±í•˜ë©° ë‹µë³€ ì™„ì„±
     
## ì‹¤í–‰ ìˆœì„œ
```
$ pip install -r requirements.txt
$ PYTHONPATH=. python3 src/run.py --rag_index  # ì™¸ë¶€ ë¬¸ì„œ ë²¡í„°í™” + ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„±
$ PYTHONPATH=. python3 src/run.py --train  # ëª¨ë¸ ìƒì„±
$ PYTHONPATH=. python3 src/run.py  --inference  # ì±—ë´‡ ì‹¤í–‰
  - You > ì…ë ¥ í›„ ëŒ€í™”
  - **quit** ì…ë ¥í•˜ë©´ ì¢…ë£Œ
```


## ğŸ”—Â ì¶œë ¥ ì˜ˆì‹œ
  ```
  Input: ì˜í™” ë³¼ê¹Œ?
  Output: ìµœì‹  ì¸ê¸° ì°¨íŠ¸ë¥¼ ì°¾ì•„ë³´ëŠ” ê±¸ ì¶”ì²œí•´ìš” .
  
  Input: ì´ì‚¬ ê°€ê³ ì‹¶ì–´
  Output: ê°€ë©´ ì €ë„ ë°ë ¤ê°€ì„¸ìš” .
  
  Input: ë‚œ ë°”ë³´ì•¼
  Output: ì‚¬ë‘í•´ì£¼ëŠ” ì‚¬ëŒì´ ìˆì„ ê±°ì˜ˆìš” .
  ```

## ğŸ“š ì°¸ê³ 
  - [Attention is All You Need](https://arxiv.org/abs/1706.03762)
  - TensorFlow ê³µì‹ ë¬¸ì„œ ë° íŠœí† ë¦¬ì–¼


## ğŸ“ Transformer êµ¬ì¡° ì •ë¦¬
  - ìì„¸í•œ êµ¬í˜„ ë° ì„¤ëª…ì€ ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ :
  [Transformer](https://scratched-bedbug-41b.notion.site/Transformer-20949b64dbf580c38cfade8b185ad3c1?source=copy_link)