'''
ğŸ”§ ëª©í‘œ
    ** ì§ë ¬ vs ë³‘ë ¬
    1. data/raw/ í´ë”ì˜ íŒŒì¼ë“¤ì„ í•˜ë‚˜ì”© ì½ê¸°
    2. ì²« 1,000ì¤„ì„ ì½ì–´ì„œ ë¹„ì—ˆìœ¼ë©´ ìŠ¤í‚µ
    3. ì§„í–‰ìƒí™©ì„ ë¡œê·¸ë¡œ ì°ê¸°
'''
import pandas as pd
import os
import re
import ray
import numpy as np
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
# warnings.filterwarnings("ignore")

# Ray ì‹œìŠ¤í…œ ì´ˆê¸°í™”
ray.init(include_dashboard=True)

# ì›ë³¸ ë°ì´í„° í´ë” ê²½ë¡œ ì„¤ì •
RAW_PATH = "data/raw"  # ì›ë³¸ ë°ì´í„°
PREPROCESS_PATH = "data/processed"  # ì „ì²˜ë¦¬ëœ ë°ì´í„°
# í´ë” ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì¤Œ, ì´ë¯¸ ìˆì–´ë„ ì—ëŸ¬ x
os.makedirs(RAW_PATH, exist_ok=True)  
os.makedirs(PREPROCESS_PATH, exist_ok=True)

file = os.listdir(RAW_PATH)  # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
# ì „ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ë§Œ í•„í„°ë§
    # ex. RAW_PATH(data/raw) + f(file, empty_file.csv) -> data/raw/empty_file.csv
csv_files = [os.path.join(RAW_PATH, f)  
             for f in file 
             if f.endswith('.csv')]

# ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess(df):
    # ë¬¸ìì—´, íŠ¹ìˆ˜ë¬¸ì íƒì§€
    special_pattern = r'[|!@#$%^&*()\-=+[\]{};:\'",.<>/?\\]'
    for col in df.select_dtypes(include=['object', 'string']).columns:
        try:
            # ì»¬ëŸ¼ì— íŠ¹ìˆ˜ë¬¸ì í¬í•¨ëœ ê°’ì´ í•˜ë‚˜ë¼ë„ ìˆë‹¤ë©´
            if df[col].str.contains(special_pattern, na=False).any():
                # íŠ¹ìˆ˜ë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ë¬¸ìì—´ ë‚˜ëˆ„ê¸° -> ì—¬ëŸ¬ ì»¬ëŸ¼ìœ¼ë¡œ
                split_cols = df[col].str.split(special_pattern, expand=True)
                # ìƒˆë¡œ ìƒê¸´ ì»¬ëŸ¼ì— ì´ë¦„ ì§€ì • ex. col_0, col_1, ...
                split_cols.columns = [f"{col}_{i}" for i in range(split_cols.shape[1])]
                # ê¸°ì¡´ ì»¬ëŸ¼ ì œê±° -> ìƒˆë¡œ ë‚˜ë‰œ ì»¬ëŸ¼ì„ dfì— ë³‘í•©
                df = pd.concat([df.drop(columns=[col]), split_cols], axis=1)
        except:
            continue  # ì˜¤ë¥˜ ë°œìƒí•˜ë©´ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰

    # ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
    datetime_cols = []
    for col in df.columns:
        try:
            # ì»¬ëŸ¼ëª…ì´ ì•„ë‹Œ ê°’ ìì²´ë¥¼ ë³´ê³  datetime ë³€í™˜ì´ ê°€ëŠ¥í•œì§€ íŒë‹¨
            # ë‚ ì§œ ë³€í™˜ì— ì‹¤íŒ¨í•œ ê°’ì€ NaT(Not a Time)ë¡œ ì²˜ë¦¬ = ë‚ ì§œì²˜ëŸ¼ ì•ˆ ìƒê¸´ ê°’ì€ ë²„ë¦¼
            parsed = pd.to_datetime(df[col], errors='coerce')
            # ë³€í™˜ëœ ê²°ê³¼ ì¤‘ì—ì„œ NaTê°€ ì•„ë‹Œ ê°’ ê°œìˆ˜ë¥¼ ì…ˆ
            # ëŒ€ë¶€ë¶„ ë‚ ì§œ/ì‹œê°„ì²˜ëŸ¼ ìƒê¸´ ê°’ì´ë¼ëŠ” ê²ƒì— ëŒ€í•œ íŒë‹¨
            if parsed.notna().sum() > len(df) * 0.5:
                datetime_cols.append(col)  # ì§„ì§œ datetimeìœ¼ë¡œ íŒë‹¨ëœ ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
                df[col] = parsed
                df[f'{col}_date'] = df[col].dt.date  # ë³€í™˜ëœ datetimeì—ì„œ ë‚ ì§œ ë¶€ë¶„ë§Œ ë¶„ë¦¬í•´ì„œ ìƒˆ ì»¬ëŸ¼ ìƒì„±
                df[f'{col}_time'] = df[col].dt.hour  # ë³€í™˜ëœ datetimeì—ì„œ ì‹œê°„ë§Œ ë¶„ë¦¬í•´ì„œ ìƒˆ ì»¬ëŸ¼ ìƒì„±
        except:
            continue
                
    # ì´ìƒì¹˜ ì²˜ë¦¬
    for col in df.select_dtypes(include=['number']).columns:
        # -1000ë³´ë‹¤ ì‘ê±°ë‚˜ 1000000ë³´ë‹¤ í° ê°’ -> ì´ìƒì¹˜, NaNìœ¼ë¡œ ì²˜ë¦¬
        df[col] = df[col].apply(lambda x: np.nan if x < -1000 or x > 1e6 else x)
        
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df = df.fillna(0)
    
    return df

@ray.remote  # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
def process_file(file_path):
    warnings.filterwarnings("ignore", message="Could not infer format")
    filename = os.path.basename(file_path)  # íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ
    output_path = os.path.join(PREPROCESS_PATH, filename)  # ì „ì²˜ë¦¬ëœ íŒŒì¼ ê²½ë¡œ
    # ì»¬ëŸ¼, ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ íŒŒì¼
    if os.path.getsize(file_path) == 0:
        return f"[Skip] Empty file(0 byte): {filename}"
        
    try:
        # ì²« 1000ì¤„ë§Œ ì½ê¸° (ëŒ€ìš©ëŸ‰ ëŒ€ë¹„)
        df = pd.read_csv(file_path, nrows=1000)  
        
        if df.empty:  # ì»¬ëŸ¼ì€ ìˆì§€ë§Œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
            return f"[SKIP] No data rows: {filename}"
        
        # íŒŒì¼ì´ ì—´ë ¸ê³ , ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œ ì „ì²˜ë¦¬ ìˆ˜í–‰
        df = preprocess(df)
        df.to_csv(output_path, index=False)  # ì „ì²˜ë¦¬ íŒŒì¼ ì €ì¥
        
        # ì •ìƒ íŒŒì¼ì¼ ê²½ìš° ê°„ë‹¨ í†µê³„ ì¶œë ¥
        return f"[OK] {filename}: shape={df.shape}, columns={df.columns.tolist()}"
            
    except Exception as e:
        return f"[ERROR] failed to read {filename}: {e}"

features = [process_file.remote(path) for path in csv_files]
results = ray.get(features)

with open("log.txt", "a") as f:
    for res in results:    
        f.write(f"{res}\n")
        print(res)
    
    
    
# ------ì§ë ¬ ì²˜ë¦¬------
# # íŒŒì¼ ìˆœì°¨ ì²˜ë¦¬
# for filename in csv_files:
#     file_path = os.path.join(RAW_PATH, filename)  # íŒŒì¼ ê²½ë¡œ ìƒì„±
#     print(f"[INFO] Processing: {filename}")  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ íŒŒì¼ ì¶œë ¥
    
#     # ì»¬ëŸ¼, ë°ì´í„°ê°€ ì—†ëŠ” ë¹ˆ íŒŒì¼
#     if os.path.getsize(file_path) == 0:
#         print(f"[Skip] Empty file(0 byte): {filename}")  
#         continue 
        
#     try:
#         # ì²« 1000ì¤„ë§Œ ì½ê¸° (ëŒ€ìš©ëŸ‰ ëŒ€ë¹„)
#         df = pd.read_csv(file_path, nrows=1000)  
        
#         if df.empty:  # ì»¬ëŸ¼ì€ ìˆì§€ë§Œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
#             print(f"[SKIP] No data rows: {filename}")
#             continue
        
#         # ì •ìƒ íŒŒì¼ì¼ ê²½ìš° ê°„ë‹¨ í†µê³„ ì¶œë ¥
#         print(f"[OK] {filename}: shape={df.shape}, columns={df.columns.tolist()}")  
            
#     except Exception as e:
#         print(f"[ERROR] failed to read {filename}: {e}")
